{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what we can quantize ? \n",
    "1- the wieghts\n",
    "2- the activation \n",
    "\n",
    "after quantization we get : \n",
    "- samller models  \n",
    "- speed gain \n",
    "- faster operation \n",
    "\n",
    "quantization after the training called POST-TRAINING QUANTIZATION \n",
    "\n",
    "\n",
    "## linear quantization is a popluar method of quantization \n",
    "\n",
    "in linear quantization we map high presision value to lower\n",
    "like fp32 to int 8 \n",
    "\n",
    "Formula : \n",
    "\n",
    "r = s(q - z)\n",
    "\n",
    "where : \n",
    "s : scale (as the original tensor)\n",
    "z : zero point (the quantized tensor)\n",
    "\n",
    "getting q : \n",
    "\n",
    "form the original formaula above \n",
    "\n",
    "r/s = q - z \n",
    "\n",
    "q = r/s + z \n",
    "\n",
    "q = round(r/s + z)\n",
    "q = int (round(r/s + z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_Q(\n",
    "        tensor,\n",
    "        scale,\n",
    "        zero,\n",
    "        dtype = torch.int8\n",
    "):\n",
    "    \n",
    "    scaled_shifted_tensor = tensor / scale + zero \n",
    "    rounded = torch.round(scaled_shifted_tensor)\n",
    "\n",
    "    q_min = torch.iinfo(dtype).min \n",
    "    q_max = torch.iinfo(dtype).max \n",
    "\n",
    "    q_tensor = rounded.clamp(q_min, q_max).to(dtype)\n",
    "\n",
    "    return q_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor(\n",
    "    [[191.5 , -13.5, 728.6],\n",
    "     [92.14, 295.5, -184],\n",
    "     [0 , 684.6 , 245.5]\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -15,  -74,  127],\n",
      "        [ -44,   14, -123],\n",
      "        [ -70,  126,    0]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "scale = 3.5 \n",
    "zero = -70 \n",
    "\n",
    "quantized_tensor = linear_Q(test_tensor,scale,zero)\n",
    "\n",
    "print(quantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 192.5000,  -14.0000,  689.5000],\n",
       "        [  91.0000,  294.0000, -185.5000],\n",
       "        [   0.0000,  686.0000,  245.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequant_tensor = scale * (quantized_tensor.float() - zero)\n",
    "dequant_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 192.5000,  -14.0000, -206.5000],\n",
       "        [  91.0000,  294.0000, -185.5000],\n",
       "        [   0.0000, -210.0000,  245.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequant_tensor = scale * (quantized_tensor- zero)\n",
    "dequant_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_DQ(quantized_tensor, scale, zero):\n",
    "    return scale * (quantized_tensor- zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting helper function for quantization error \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear quantization mao [rmin , rmax] to the [qmin , qmax]\n",
    "\n",
    "rmin = s(qmin - z)\n",
    "rmax = s(qmax - z)\n",
    "\n",
    "so for s : \n",
    "\n",
    "s = (rmax -rmin) / (qmax -qmin)\n",
    "\n",
    "and for z: \n",
    "\n",
    "z = int(round(qmin - rmin / s) --> same data type as quantized tensor\n",
    "\n",
    "\n",
    "for the prevuos example find s and z ? \n",
    "\n",
    "\n",
    "handling the edge cases for z \n",
    "what happen if tyhe zero value is out of range \n",
    "\n",
    "if z > qmax >> z = qmax \n",
    "if z < qmin >> z = qmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale_and_zero_values(\n",
    "        r_tensor,\n",
    "        dtype = torch.int8\n",
    "):\n",
    "    q_max , q_min = torch.iinfo(dtype).max , torch.iinfo(dtype).min \n",
    "    r_min , r_max  = r_tensor.min().item() , r_tensor.max().item()\n",
    "\n",
    "    scale = (r_max - r_min) / (q_max - q_min) \n",
    "    z = q_min - (r_min/scale)\n",
    "\n",
    "    if q_min <=z <= q_max :\n",
    "        z = int(round(z))\n",
    "    elif z < q_min : \n",
    "        z = q_min \n",
    "    elif z < q_max : \n",
    "        z = q_max\n",
    "\n",
    "    return scale , z \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.578823433670343\n",
      "-77\n"
     ]
    }
   ],
   "source": [
    "new_scale , new_zero = get_scale_and_zero_values(test_tensor, torch.int8)\n",
    "\n",
    "print(new_scale)\n",
    "print(new_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor = linear_Q(test_tensor, new_scale, new_zero)\n",
    "dequant_tensor = linear_DQ (quantized_tensor, new_scale, new_zero) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -23,  -81,  127],\n",
      "        [ -51,    6, -128],\n",
      "        [ -77,  114,   -8]], dtype=torch.int8)\n",
      "tensor([[ 193.2565,  -14.3153, -186.0988],\n",
      "        [  93.0494,  297.0423, -182.5200],\n",
      "        [   0.0000, -232.6235,  246.9388]])\n"
     ]
    }
   ],
   "source": [
    "print(quantized_tensor)\n",
    "print(dequant_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the error again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a general linear quantazation funcion:\n",
    "def linear_quantizer(tensor,dtype = torch.int8):\n",
    "    scale , zero_point = get_scale_and_zero_values(tensor, dtype=dtype)\n",
    "    quantized_tensor = linear_Q(tensor, scale , zero_point, dtype=dtype)\n",
    "    return quantized_tensor , scale , zero_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7720, -0.7745,  1.0395,  0.3962],\n",
       "        [-0.2456, -0.2868, -1.5821, -0.9948],\n",
       "        [ 0.2450, -0.1396, -0.5027,  0.1406],\n",
       "        [ 0.3538, -1.8619,  1.3330, -0.5275]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_tensor = torch.randn((4,4))\n",
    "r_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_tensor , scale , zero = linear_quantizer(r_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  83,  -41,  104,   53],\n",
       "        [   1,   -2, -105,  -58],\n",
       "        [  41,   10,  -19,   32],\n",
       "        [  49, -128,  127,  -21]], dtype=torch.int8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01252906649720435"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
