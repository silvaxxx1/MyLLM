C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\trainer\ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.
  warnings.warn(
Device set to use cpu
2025-01-09 22:21:35,129 [INFO] Example sentiment analysis:
C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\pipelines\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.
  warnings.warn(
2025-01-09 22:21:35,663 [INFO] Sentiment for 'bad' movie text: [[{'label': 'NEGATIVE', 'score': 2.335048198699951}, {'label': 'POSITIVE', 'score': -2.7265758514404297}]]
2025-01-09 22:21:35,663 [INFO] Printing a sample of the reward computation:
2025-01-09 22:21:35,694 [INFO] Sentiment for 'good' movie text: [[{'label': 'NEGATIVE', 'score': -2.294790267944336}, {'label': 'POSITIVE', 'score': 2.557039976119995}]]
2025-01-09 22:21:35,698 [INFO] Starting PPO alignment...
0it [00:00, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
0it [00:41, ?it/s]
Traceback (most recent call last):
  File "C:\Users\WinDows\SILVA\MyLLM_101_from_scratch\finetuning\GPT2_RLHF_PPO\PPO.py", line 122, in <module>
    response = ppo_trainer.generate(query, **response_generation_kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\trainer\ppo_trainer.py", line 523, in generate
    response = unwrapped_model.generate(input_ids=query_tensor.unsqueeze(dim=0), **generation_kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\models\modeling_value_head.py", line 207, in generate
    return self.pretrained_model.generate(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\generation\utils.py", line 2252, in generate
    result = self._sample(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\generation\utils.py", line 3254, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1272, in forward
    transformer_outputs = self.transformer(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1133, in forward
    outputs = block(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 652, in forward
    feed_forward_hidden_states = self.mlp(hidden_states)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 577, in forward
    hidden_states = self.c_proj(hidden_states)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
KeyboardInterrupt
Traceback (most recent call last):
  File "C:\Users\WinDows\SILVA\MyLLM_101_from_scratch\finetuning\GPT2_RLHF_PPO\PPO.py", line 122, in <module>
    response = ppo_trainer.generate(query, **response_generation_kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\trainer\ppo_trainer.py", line 523, in generate
    response = unwrapped_model.generate(input_ids=query_tensor.unsqueeze(dim=0), **generation_kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\models\modeling_value_head.py", line 207, in generate
    return self.pretrained_model.generate(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\generation\utils.py", line 2252, in generate
    result = self._sample(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\generation\utils.py", line 3254, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1272, in forward
    transformer_outputs = self.transformer(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1133, in forward
    outputs = block(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 652, in forward
    feed_forward_hidden_states = self.mlp(hidden_states)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 577, in forward
    hidden_states = self.c_proj(hidden_states)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
KeyboardInterrupt
