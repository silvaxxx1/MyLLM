C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\trainer\ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.
  warnings.warn(
Device set to use cpu
2025-01-09 21:23:07,753 [INFO] Example sentiment analysis:
C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\pipelines\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.
  warnings.warn(
2025-01-09 21:23:08,218 [INFO] Sentiment for 'bad' movie text: [[{'label': 'NEGATIVE', 'score': 2.335048198699951}, {'label': 'POSITIVE', 'score': -2.7265758514404297}]]
2025-01-09 21:23:08,224 [INFO] Printing a sample of the reward computation:
2025-01-09 21:23:08,251 [INFO] Sentiment for 'good' movie text: [[{'label': 'NEGATIVE', 'score': -2.294790267944336}, {'label': 'POSITIVE', 'score': 2.557039976119995}]]
2025-01-09 21:23:08,251 [INFO] Starting PPO alignment...
0it [00:00, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
0it [00:48, ?it/s]
Traceback (most recent call last):
  File "C:\Users\WinDows\SILVA\MyLLM_101_from_scratch\finetuning\GPT2_RLHF_PPO\PPO.py", line 133, in <module>
    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\trainer\ppo_trainer.py", line 748, in step
    all_logprobs, logits_or_none, values, masks = self.batched_forward_pass(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\trainer\ppo_trainer.py", line 1022, in batched_forward_pass
    logits, _, values = model(**input_kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\models\modeling_value_head.py", line 171, in forward
    base_model_output = self.pretrained_model(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1272, in forward
    transformer_outputs = self.transformer(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1133, in forward
    outputs = block(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 652, in forward
    feed_forward_hidden_states = self.mlp(hidden_states)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 577, in forward
    hidden_states = self.c_proj(hidden_states)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\pytorch_utils.py", line 121, in forward
    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)
KeyboardInterrupt
Traceback (most recent call last):
  File "C:\Users\WinDows\SILVA\MyLLM_101_from_scratch\finetuning\GPT2_RLHF_PPO\PPO.py", line 133, in <module>
    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\trainer\ppo_trainer.py", line 748, in step
    all_logprobs, logits_or_none, values, masks = self.batched_forward_pass(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\trainer\ppo_trainer.py", line 1022, in batched_forward_pass
    logits, _, values = model(**input_kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\trl\models\modeling_value_head.py", line 171, in forward
    base_model_output = self.pretrained_model(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1272, in forward
    transformer_outputs = self.transformer(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1133, in forward
    outputs = block(
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 652, in forward
    feed_forward_hidden_states = self.mlp(hidden_states)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 577, in forward
    hidden_states = self.c_proj(hidden_states)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\WinDows\anaconda3\envs\LLM\lib\site-packages\transformers\pytorch_utils.py", line 121, in forward
    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)
KeyboardInterrupt
