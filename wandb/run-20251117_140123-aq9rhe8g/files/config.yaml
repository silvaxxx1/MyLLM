_wandb:
    value:
        cli_version: 0.21.4
        e:
            k21w2g79kbxz2ccvxgh7ep78pfrs77xx:
                cpu_count: 4
                cpu_count_logical: 8
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "982238978048"
                        used: "352337850368"
                email: silvapi1994@gmail.com
                executable: /home/silva/SILVA.AI/Projects/MyLLM/.venv/bin/python
                git:
                    commit: cd9d22cdcee10373ee75f6b92572de682740183c
                    remote: git@github.com:silvaxxx1/MyLLM.git
                gpu: NVIDIA GeForce GTX 1650
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Turing
                      cudaCores: 1024
                      memoryTotal: "4294967296"
                      name: NVIDIA GeForce GTX 1650
                      uuid: GPU-605b6ad0-c95a-c7a0-f428-928e6885f80f
                host: SilvaLAB
                memory:
                    total: "14521053184"
                os: Linux-6.14.0-35-generic-x86_64-with-glibc2.39
                program: -m myllm.Train.tests.sft_test
                python: CPython 3.12.3
                root: /home/silva/SILVA.AI/Projects/MyLLM
                startedAt: "2025-11-17T11:01:23.918349Z"
                writerId: k21w2g79kbxz2ccvxgh7ep78pfrs77xx
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 2
                - 3
                - 5
                - 49
                - 53
            "2":
                - 1
                - 2
                - 3
                - 5
                - 49
                - 53
            "3":
                - 13
                - 15
                - 16
                - 61
            "4": 3.12.3
            "5": 0.21.4
            "12": 0.21.4
            "13": linux-x86_64
batch_size:
    value: 2
gradient_accumulation_steps:
    value: 1
learning_rate:
    value: 0.0003
max_grad_norm:
    value: 1
model_config_name:
    value: gpt2-small
num_epochs:
    value: 2
tokenizer_name:
    value: gpt2
warmup_steps:
    value: 10
